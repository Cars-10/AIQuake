{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# This will reload all modules before executing a new line\n",
    "# This is important, if we change our modules, we don't have to restart the kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import loading_data as ld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = ld.load_train_values()\n",
    "df_label = ld.load_train_labels()\n",
    "df_test = ld.load_test_values()\n",
    "\n",
    "# integrate damage_grade into train_values\n",
    "df_train['damage_grade'] = df_label['damage_grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(260601, 40)\n",
      "(260601, 2)\n",
      "(86868, 39)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_label.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Data type  Any nulls?  Unique values\n",
      "building_id                                int64       False         260601\n",
      "geo_level_1_id                             int64       False             31\n",
      "geo_level_2_id                             int64       False           1414\n",
      "geo_level_3_id                             int64       False          11595\n",
      "count_floors_pre_eq                        int64       False              9\n",
      "age                                        int64       False             42\n",
      "area_percentage                            int64       False             84\n",
      "height_percentage                          int64       False             27\n",
      "land_surface_condition                    object       False              3\n",
      "foundation_type                           object       False              5\n",
      "roof_type                                 object       False              3\n",
      "ground_floor_type                         object       False              5\n",
      "other_floor_type                          object       False              4\n",
      "position                                  object       False              4\n",
      "plan_configuration                        object       False             10\n",
      "has_superstructure_adobe_mud               int64       False              2\n",
      "has_superstructure_mud_mortar_stone        int64       False              2\n",
      "has_superstructure_stone_flag              int64       False              2\n",
      "has_superstructure_cement_mortar_stone     int64       False              2\n",
      "has_superstructure_mud_mortar_brick        int64       False              2\n",
      "has_superstructure_cement_mortar_brick     int64       False              2\n",
      "has_superstructure_timber                  int64       False              2\n",
      "has_superstructure_bamboo                  int64       False              2\n",
      "has_superstructure_rc_non_engineered       int64       False              2\n",
      "has_superstructure_rc_engineered           int64       False              2\n",
      "has_superstructure_other                   int64       False              2\n",
      "legal_ownership_status                    object       False              4\n",
      "count_families                             int64       False             10\n",
      "has_secondary_use                          int64       False              2\n",
      "has_secondary_use_agriculture              int64       False              2\n",
      "has_secondary_use_hotel                    int64       False              2\n",
      "has_secondary_use_rental                   int64       False              2\n",
      "has_secondary_use_institution              int64       False              2\n",
      "has_secondary_use_school                   int64       False              2\n",
      "has_secondary_use_industry                 int64       False              2\n",
      "has_secondary_use_health_post              int64       False              2\n",
      "has_secondary_use_gov_office               int64       False              2\n",
      "has_secondary_use_use_police               int64       False              2\n",
      "has_secondary_use_other                    int64       False              2\n",
      "damage_grade                               int64       False              3\n"
     ]
    }
   ],
   "source": [
    "df_train_summary = pd.DataFrame({\n",
    "    \"Data type\": df_train.dtypes,\n",
    "    \"Any nulls?\": df_train.isnull().any(),\n",
    "    \"Unique values\": df_train.nunique()\n",
    "})\n",
    "print(df_train_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is no null, no data cleaning yet. (for rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import balancing_data as bd\n",
    "\n",
    "df_train_balanced, df_label_balanced = bd.balance_dataset(df_train, df_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning, Dropping the unnecessary columns, Encoding the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 4 columns from the dataframe.\n",
      "List of columns to drop:\n",
      "0:\tposition\n",
      "1:\tplan_configuration\n",
      "2:\tlegal_ownership_status\n",
      "3:\tdamage_grade\n",
      "\n",
      "One-hot encoding 5 columns.\n",
      "List of columns to one-hot encode:\n",
      "0:\tland_surface_condition\n",
      "1:\tfoundation_type\n",
      "2:\troof_type\n",
      "3:\tground_floor_type\n",
      "4:\tother_floor_type\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import feature_engineering as fe\n",
    "import geolocation_encoding as ge\n",
    "\n",
    "df_geolocation_encoding = ge.encode_geolocation(df_train_balanced)\n",
    "df_train_engineered = fe.engineer_features(df_geolocation_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 260601 entries, 0 to 260600\n",
      "Data columns (total 52 columns):\n",
      " #   Column                                  Non-Null Count   Dtype  \n",
      "---  ------                                  --------------   -----  \n",
      " 0   building_id                             260601 non-null  int64  \n",
      " 1   geo_level_1_id                          260601 non-null  int64  \n",
      " 2   geo_level_2_id                          260601 non-null  int64  \n",
      " 3   geo_level_3_id                          260601 non-null  int64  \n",
      " 4   count_floors_pre_eq                     260601 non-null  int64  \n",
      " 5   age                                     260601 non-null  int64  \n",
      " 6   area_percentage                         260601 non-null  int64  \n",
      " 7   height_percentage                       260601 non-null  int64  \n",
      " 8   has_superstructure_adobe_mud            260601 non-null  int64  \n",
      " 9   has_superstructure_mud_mortar_stone     260601 non-null  int64  \n",
      " 10  has_superstructure_stone_flag           260601 non-null  int64  \n",
      " 11  has_superstructure_cement_mortar_stone  260601 non-null  int64  \n",
      " 12  has_superstructure_mud_mortar_brick     260601 non-null  int64  \n",
      " 13  has_superstructure_cement_mortar_brick  260601 non-null  int64  \n",
      " 14  has_superstructure_timber               260601 non-null  int64  \n",
      " 15  has_superstructure_bamboo               260601 non-null  int64  \n",
      " 16  has_superstructure_rc_non_engineered    260601 non-null  int64  \n",
      " 17  has_superstructure_rc_engineered        260601 non-null  int64  \n",
      " 18  has_superstructure_other                260601 non-null  int64  \n",
      " 19  count_families                          260601 non-null  int64  \n",
      " 20  has_secondary_use                       260601 non-null  int64  \n",
      " 21  has_secondary_use_agriculture           260601 non-null  int64  \n",
      " 22  has_secondary_use_hotel                 260601 non-null  int64  \n",
      " 23  has_secondary_use_rental                260601 non-null  int64  \n",
      " 24  has_secondary_use_institution           260601 non-null  int64  \n",
      " 25  has_secondary_use_school                260601 non-null  int64  \n",
      " 26  has_secondary_use_industry              260601 non-null  int64  \n",
      " 27  has_secondary_use_health_post           260601 non-null  int64  \n",
      " 28  has_secondary_use_gov_office            260601 non-null  int64  \n",
      " 29  has_secondary_use_use_police            260601 non-null  int64  \n",
      " 30  has_secondary_use_other                 260601 non-null  int64  \n",
      " 31  geo_level_3_id_mean_damage              260601 non-null  float64\n",
      " 32  land_surface_condition_n                260601 non-null  bool   \n",
      " 33  land_surface_condition_o                260601 non-null  bool   \n",
      " 34  land_surface_condition_t                260601 non-null  bool   \n",
      " 35  foundation_type_h                       260601 non-null  bool   \n",
      " 36  foundation_type_i                       260601 non-null  bool   \n",
      " 37  foundation_type_r                       260601 non-null  bool   \n",
      " 38  foundation_type_u                       260601 non-null  bool   \n",
      " 39  foundation_type_w                       260601 non-null  bool   \n",
      " 40  roof_type_n                             260601 non-null  bool   \n",
      " 41  roof_type_q                             260601 non-null  bool   \n",
      " 42  roof_type_x                             260601 non-null  bool   \n",
      " 43  ground_floor_type_f                     260601 non-null  bool   \n",
      " 44  ground_floor_type_m                     260601 non-null  bool   \n",
      " 45  ground_floor_type_v                     260601 non-null  bool   \n",
      " 46  ground_floor_type_x                     260601 non-null  bool   \n",
      " 47  ground_floor_type_z                     260601 non-null  bool   \n",
      " 48  other_floor_type_j                      260601 non-null  bool   \n",
      " 49  other_floor_type_q                      260601 non-null  bool   \n",
      " 50  other_floor_type_s                      260601 non-null  bool   \n",
      " 51  other_floor_type_x                      260601 non-null  bool   \n",
      "dtypes: bool(20), float64(1), int64(31)\n",
      "memory usage: 68.6 MB\n"
     ]
    }
   ],
   "source": [
    "df_train_engineered.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling: Selection and Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models as md\n",
    "\n",
    "X_train, X_test, y_train, y_test, rf_model = md.make_and_return_model(df_train_engineered, df_label_balanced)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7440570979067938"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions\n",
    "preds = rf_model.predict(X_test)\n",
    "\n",
    "# We want to evaluate our model with micro average f1 score\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, preds, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictions**\n",
    "\n",
    "01: 0.5682738243702155\n",
    "\n",
    "02: 0.7203046756585638"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.53      0.60      5170\n",
      "           2       0.74      0.84      0.79     29487\n",
      "           3       0.76      0.64      0.69     17464\n",
      "\n",
      "    accuracy                           0.74     52121\n",
      "   macro avg       0.73      0.67      0.70     52121\n",
      "weighted avg       0.74      0.74      0.74     52121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How is the model doing on each class?\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: It's doing really bad on class 3, which is the second most common class.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Predictions Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the predictions for the competition\n",
    "Format for the submission file (csv):\n",
    "\n",
    "building_id,damage_grade\n",
    "11456,1\n",
    "16528,1\n",
    "3253,1\n",
    "18614,1\n",
    "1544,1\n",
    "\n",
    "(all numbers need to be integers!)\n",
    "\n",
    "Steps:\n",
    "* make a dataframe with the building_id\n",
    "* add the predictions to the dataframe (damage_grade)\n",
    "* make building_id the index\n",
    "* save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 4 columns from the dataframe.\n",
      "List of columns to drop:\n",
      "0:\tposition\n",
      "1:\tplan_configuration\n",
      "2:\tlegal_ownership_status\n",
      "3:\tdamage_grade\n",
      "\n",
      "One-hot encoding 5 columns.\n",
      "List of columns to one-hot encode:\n",
      "0:\tland_surface_condition\n",
      "1:\tfoundation_type\n",
      "2:\troof_type\n",
      "3:\tground_floor_type\n",
      "4:\tother_floor_type\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (260601) does not match length of index (86868)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/johannes/Repositories/DSR/10_mini_competition/AIQuake/src/Main_load_to_upload.ipynb Cell 25\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/johannes/Repositories/DSR/10_mini_competition/AIQuake/src/Main_load_to_upload.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m df_test_pred \u001b[39m=\u001b[39m df_test[[\u001b[39m'\u001b[39m\u001b[39mbuilding_id\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/johannes/Repositories/DSR/10_mini_competition/AIQuake/src/Main_load_to_upload.ipynb#X33sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Predictions adding to the dataframe\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/johannes/Repositories/DSR/10_mini_competition/AIQuake/src/Main_load_to_upload.ipynb#X33sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m df_test_pred[\u001b[39m'\u001b[39;49m\u001b[39mdamage_grade\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m=\u001b[39m rf_model\u001b[39m.\u001b[39mpredict(df_test_engineered)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/johannes/Repositories/DSR/10_mini_competition/AIQuake/src/Main_load_to_upload.ipynb#X33sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# making building_id the index\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/johannes/Repositories/DSR/10_mini_competition/AIQuake/src/Main_load_to_upload.ipynb#X33sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m df_test_pred\u001b[39m.\u001b[39mset_index(\u001b[39m'\u001b[39m\u001b[39mbuilding_id\u001b[39m\u001b[39m'\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/dsr-13sep/lib/python3.10/site-packages/pandas/core/frame.py:3950\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3947\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3948\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3949\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[0;32m-> 3950\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[0;32m~/anaconda3/envs/dsr-13sep/lib/python3.10/site-packages/pandas/core/frame.py:4143\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4133\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4134\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4135\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4136\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4141\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4142\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4143\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[1;32m   4145\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   4146\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m   4147\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   4148\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   4149\u001b[0m     ):\n\u001b[1;32m   4150\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4151\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/anaconda3/envs/dsr-13sep/lib/python3.10/site-packages/pandas/core/frame.py:4870\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4867\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[1;32m   4869\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4870\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[1;32m   4871\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/dsr-13sep/lib/python3.10/site-packages/pandas/core/common.py:576\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    575\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[0;32m--> 576\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    577\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (260601) does not match length of index (86868)"
     ]
    }
   ],
   "source": [
    "# Doing the same preprocessing steps as we did for the training data\n",
    "df_geolocation_encoding = ge.encode_geolocation(df_train_balanced, [])\n",
    "df_test_engineered = fe.engineer_features(df_geolocation_encoding, do_fit=False)\n",
    "\n",
    "# dataframe with the building_id column\n",
    "df_test_pred = df_test[['building_id']]\n",
    "\n",
    "# Predictions adding to the dataframe\n",
    "df_test_pred['damage_grade'] = rf_model.predict(df_test_engineered)\n",
    "\n",
    "# making building_id the index\n",
    "df_test_pred.set_index('building_id', inplace=True)\n",
    "\n",
    "# Saving the dataframe to a csv file\n",
    "df_test_pred.to_csv('../data/submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submissions**\n",
    "\n",
    "01 by Johannes: 0.5683"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsr-13sep",
   "language": "python",
   "name": "dsr-13sep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
