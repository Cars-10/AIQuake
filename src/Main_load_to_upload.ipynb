{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# This will reload all modules before executing a new line\n",
    "# This is important, if we change our modules, we don't have to restart the kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import loading_data as ld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = ld.load_train_values()\n",
    "df_label = ld.load_train_labels()\n",
    "df_test = ld.load_test_values()\n",
    "\n",
    "# integrate damage_grade into train_values\n",
    "# df_train['damage_grade'] = df_label['damage_grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(260601, 39)\n",
      "(260601, 2)\n",
      "(86868, 39)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_label.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Data type  Any nulls?  Unique values\n",
      "building_id                                int64       False         260601\n",
      "geo_level_1_id                             int64       False             31\n",
      "geo_level_2_id                             int64       False           1414\n",
      "geo_level_3_id                             int64       False          11595\n",
      "count_floors_pre_eq                        int64       False              9\n",
      "age                                        int64       False             42\n",
      "area_percentage                            int64       False             84\n",
      "height_percentage                          int64       False             27\n",
      "land_surface_condition                    object       False              3\n",
      "foundation_type                           object       False              5\n",
      "roof_type                                 object       False              3\n",
      "ground_floor_type                         object       False              5\n",
      "other_floor_type                          object       False              4\n",
      "position                                  object       False              4\n",
      "plan_configuration                        object       False             10\n",
      "has_superstructure_adobe_mud               int64       False              2\n",
      "has_superstructure_mud_mortar_stone        int64       False              2\n",
      "has_superstructure_stone_flag              int64       False              2\n",
      "has_superstructure_cement_mortar_stone     int64       False              2\n",
      "has_superstructure_mud_mortar_brick        int64       False              2\n",
      "has_superstructure_cement_mortar_brick     int64       False              2\n",
      "has_superstructure_timber                  int64       False              2\n",
      "has_superstructure_bamboo                  int64       False              2\n",
      "has_superstructure_rc_non_engineered       int64       False              2\n",
      "has_superstructure_rc_engineered           int64       False              2\n",
      "has_superstructure_other                   int64       False              2\n",
      "legal_ownership_status                    object       False              4\n",
      "count_families                             int64       False             10\n",
      "has_secondary_use                          int64       False              2\n",
      "has_secondary_use_agriculture              int64       False              2\n",
      "has_secondary_use_hotel                    int64       False              2\n",
      "has_secondary_use_rental                   int64       False              2\n",
      "has_secondary_use_institution              int64       False              2\n",
      "has_secondary_use_school                   int64       False              2\n",
      "has_secondary_use_industry                 int64       False              2\n",
      "has_secondary_use_health_post              int64       False              2\n",
      "has_secondary_use_gov_office               int64       False              2\n",
      "has_secondary_use_use_police               int64       False              2\n",
      "has_secondary_use_other                    int64       False              2\n"
     ]
    }
   ],
   "source": [
    "df_train_summary = pd.DataFrame({\n",
    "    \"Data type\": df_train.dtypes,\n",
    "    \"Any nulls?\": df_train.isnull().any(),\n",
    "    \"Unique values\": df_train.nunique()\n",
    "})\n",
    "print(df_train_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is no null, no data cleaning yet. (for rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import balancing_data as bd\n",
    "\n",
    "df_train_balanced, df_label_balanced = bd.balance_dataset(df_train, df_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning, Dropping the unnecessary columns, Encoding the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 3 columns from the dataframe.\n",
      "List of columns to drop:\n",
      "0:\tposition\n",
      "1:\tplan_configuration\n",
      "2:\tlegal_ownership_status\n",
      "\n",
      "One-hot encoding 5 columns.\n",
      "List of columns to one-hot encode:\n",
      "0:\tland_surface_condition\n",
      "1:\tfoundation_type\n",
      "2:\troof_type\n",
      "3:\tground_floor_type\n",
      "4:\tother_floor_type\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import feature_engineering as fe\n",
    "import geolocation_encoding as ge\n",
    "\n",
    "df_geolocation_encoding, mean_damage_maps = ge.encode_geolocation(df_train_balanced, df_label=df_label_balanced)\n",
    "df_train_engineered = fe.engineer_features(df_geolocation_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 260601 entries, 0 to 260600\n",
      "Data columns (total 53 columns):\n",
      " #   Column                                  Non-Null Count   Dtype  \n",
      "---  ------                                  --------------   -----  \n",
      " 0   building_id                             260601 non-null  int64  \n",
      " 1   geo_level_1_id                          260601 non-null  int64  \n",
      " 2   geo_level_2_id                          260601 non-null  int64  \n",
      " 3   geo_level_3_id                          260601 non-null  int64  \n",
      " 4   count_floors_pre_eq                     260601 non-null  int64  \n",
      " 5   age                                     260601 non-null  int64  \n",
      " 6   area_percentage                         260601 non-null  int64  \n",
      " 7   height_percentage                       260601 non-null  int64  \n",
      " 8   has_superstructure_adobe_mud            260601 non-null  int64  \n",
      " 9   has_superstructure_mud_mortar_stone     260601 non-null  int64  \n",
      " 10  has_superstructure_stone_flag           260601 non-null  int64  \n",
      " 11  has_superstructure_cement_mortar_stone  260601 non-null  int64  \n",
      " 12  has_superstructure_mud_mortar_brick     260601 non-null  int64  \n",
      " 13  has_superstructure_cement_mortar_brick  260601 non-null  int64  \n",
      " 14  has_superstructure_timber               260601 non-null  int64  \n",
      " 15  has_superstructure_bamboo               260601 non-null  int64  \n",
      " 16  has_superstructure_rc_non_engineered    260601 non-null  int64  \n",
      " 17  has_superstructure_rc_engineered        260601 non-null  int64  \n",
      " 18  has_superstructure_other                260601 non-null  int64  \n",
      " 19  count_families                          260601 non-null  int64  \n",
      " 20  has_secondary_use                       260601 non-null  int64  \n",
      " 21  has_secondary_use_agriculture           260601 non-null  int64  \n",
      " 22  has_secondary_use_hotel                 260601 non-null  int64  \n",
      " 23  has_secondary_use_rental                260601 non-null  int64  \n",
      " 24  has_secondary_use_institution           260601 non-null  int64  \n",
      " 25  has_secondary_use_school                260601 non-null  int64  \n",
      " 26  has_secondary_use_industry              260601 non-null  int64  \n",
      " 27  has_secondary_use_health_post           260601 non-null  int64  \n",
      " 28  has_secondary_use_gov_office            260601 non-null  int64  \n",
      " 29  has_secondary_use_use_police            260601 non-null  int64  \n",
      " 30  has_secondary_use_other                 260601 non-null  int64  \n",
      " 31  geo_level_1_id_mean_damage              260601 non-null  float64\n",
      " 32  geo_level_2_id_mean_damage              260601 non-null  float64\n",
      " 33  land_surface_condition_n                260601 non-null  bool   \n",
      " 34  land_surface_condition_o                260601 non-null  bool   \n",
      " 35  land_surface_condition_t                260601 non-null  bool   \n",
      " 36  foundation_type_h                       260601 non-null  bool   \n",
      " 37  foundation_type_i                       260601 non-null  bool   \n",
      " 38  foundation_type_r                       260601 non-null  bool   \n",
      " 39  foundation_type_u                       260601 non-null  bool   \n",
      " 40  foundation_type_w                       260601 non-null  bool   \n",
      " 41  roof_type_n                             260601 non-null  bool   \n",
      " 42  roof_type_q                             260601 non-null  bool   \n",
      " 43  roof_type_x                             260601 non-null  bool   \n",
      " 44  ground_floor_type_f                     260601 non-null  bool   \n",
      " 45  ground_floor_type_m                     260601 non-null  bool   \n",
      " 46  ground_floor_type_v                     260601 non-null  bool   \n",
      " 47  ground_floor_type_x                     260601 non-null  bool   \n",
      " 48  ground_floor_type_z                     260601 non-null  bool   \n",
      " 49  other_floor_type_j                      260601 non-null  bool   \n",
      " 50  other_floor_type_q                      260601 non-null  bool   \n",
      " 51  other_floor_type_s                      260601 non-null  bool   \n",
      " 52  other_floor_type_x                      260601 non-null  bool   \n",
      "dtypes: bool(20), float64(2), int64(31)\n",
      "memory usage: 70.6 MB\n"
     ]
    }
   ],
   "source": [
    "df_train_engineered.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling: Selection and Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models as md\n",
    "\n",
    "X_train, X_test, y_train, y_test, rf_model = md.make_and_return_model(df_train_engineered, df_label_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7396251031254197"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions\n",
    "preds = rf_model.predict(X_test)\n",
    "\n",
    "# We want to evaluate our model with micro average f1 score\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, preds, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictions**\n",
    "\n",
    "01: 0.5682738243702155\n",
    "\n",
    "02: 0.7203046756585638\n",
    "\n",
    "These predictions were greate on the training set, but not on the test set:\n",
    "\n",
    "03: 0.7440570979067938\n",
    "\n",
    "04: 0.7444408203986875\n",
    "\n",
    "Here we got also good results on the test set:\n",
    "\n",
    "05: 0.7328140288943037"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.52      0.58      5025\n",
      "           2       0.74      0.84      0.79     29652\n",
      "           3       0.75      0.64      0.69     17444\n",
      "\n",
      "    accuracy                           0.74     52121\n",
      "   macro avg       0.72      0.67      0.69     52121\n",
      "weighted avg       0.74      0.74      0.74     52121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How is the model doing on each class?\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: It's doing really bad on class 3, which is the second most common class.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Predictions Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the predictions for the competition\n",
    "Format for the submission file (csv):\n",
    "\n",
    "building_id,damage_grade\n",
    "11456,1\n",
    "16528,1\n",
    "3253,1\n",
    "18614,1\n",
    "1544,1\n",
    "\n",
    "(all numbers need to be integers!)\n",
    "\n",
    "Steps:\n",
    "* make a dataframe with the building_id\n",
    "* add the predictions to the dataframe (damage_grade)\n",
    "* make building_id the index\n",
    "* save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geo_level_1_id_mean_damage column has 0 NaN values, which getting filled with mean 2.1798668693427175\n",
      "geo_level_2_id_mean_damage column has 5 NaN values, which getting filled with mean 2.215149104061613\n",
      "Dropping 3 columns from the dataframe.\n",
      "List of columns to drop:\n",
      "0:\tposition\n",
      "1:\tplan_configuration\n",
      "2:\tlegal_ownership_status\n",
      "\n",
      "One-hot encoding 5 columns.\n",
      "List of columns to one-hot encode:\n",
      "0:\tland_surface_condition\n",
      "1:\tfoundation_type\n",
      "2:\troof_type\n",
      "3:\tground_floor_type\n",
      "4:\tother_floor_type\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Doing the same preprocessing steps as we did for the training data\n",
    "df_geolocation_encoding, _ = ge.encode_geolocation(df_test, mean_damage_maps=mean_damage_maps)\n",
    "df_test_engineered = fe.engineer_features(df_geolocation_encoding, do_fit=False)\n",
    "\n",
    "# dataframe with the building_id column\n",
    "df_test_pred = df_test[['building_id']]\n",
    "\n",
    "# Print shape of the engineered test dataframe and df_test_pred\n",
    "# print(df_test_engineered.shape)\n",
    "# print(df_test_pred.shape)\n",
    "\n",
    "df_test_pred = df_test_pred.copy()\n",
    "# Predictions adding to the dataframe\n",
    "df_test_pred['damage_grade'] = rf_model.predict(df_test_engineered)\n",
    "\n",
    "# making building_id the index\n",
    "df_test_pred.set_index('building_id', inplace=True)\n",
    "\n",
    "# Saving the dataframe to a csv file\n",
    "df_test_pred.to_csv('../data/submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submissions**\n",
    "\n",
    "01 by Johannes: 0.5683\n",
    "\n",
    "02 by Johannes: 0.58..\n",
    "\n",
    "03 by Johannes: 0.7342"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "09_Trees",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
